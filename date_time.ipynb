{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-18 14:37:27.838226\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_date_time  = datetime.now()\n",
    "print(current_date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_time(entities):\n",
    "    from datetime import datetime\n",
    "    valid_date = True\n",
    "    entities = entities.replace(\"T\",\" \").split(\".\")[0]\n",
    "    print(entities)\n",
    "\n",
    "    current_date_time = datetime.now()\n",
    "    date_format = '%Y-%m-%d %H:%M:%S'\n",
    "    date_obj = datetime.strptime(entities, date_format)\n",
    "    \n",
    "    if date_obj < current_date_time:\n",
    "        valid_date = False\n",
    "        return valid_date, None\n",
    "    \n",
    "    today9am = date_obj.replace(hour=9, minute=0, second=0)\n",
    "    today7pm = date_obj.replace(hour=19, minute=0, second=0)\n",
    "    \n",
    "    is_valid_time = False\n",
    "    if today9am <= date_obj <= today7pm:\n",
    "        is_valid_time = True\n",
    "    date = date_obj.strftime(\"%d/%m/%Y\")\n",
    "    time = date_obj.strftime(\"%H:%M\")\n",
    "    final_dt = \"\"\n",
    "    if is_valid_time:\n",
    "        final_dt= f\" at {time}\" \n",
    "    final_dt += f\" on {date}.\"\n",
    "    \n",
    "    return valid_date,final_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-22 18:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = '2023-12-22T18:00:00.000+00:00'\n",
    "get_date_time(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get last 15 dates in \"dd/mm/yy\" formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01/04/23', '31/03/23', '30/03/23', '29/03/23', '28/03/23', '27/03/23', '26/03/23', '25/03/23', '24/03/23', '23/03/23', '22/03/23', '21/03/23', '20/03/23', '19/03/23', '18/03/23']\n"
     ]
    }
   ],
   "source": [
    "def get_last_15_dates(input_date):\n",
    "    from datetime import datetime, timedelta\n",
    "    datetime_object = datetime.strptime(input_date, '%d/%m/%y')\n",
    "    list_of_last_15_days_date = []\n",
    "    for i in range(0,15):\n",
    "        l = (datetime_object - timedelta(days=int(i))).strftime('%d/%m/%y')\n",
    "        list_of_last_15_days_date.append(str(l))\n",
    "    return list_of_last_15_days_date\n",
    "print(get_last_15_dates(\"01/04/23\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Time to \"dd/mm/yy\" string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n",
      "2023-04-18 16:50:10.602465\n",
      "18/04/23\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "datetime_str = \"01/04/23\"\n",
    "yesterday = datetime.now() - timedelta(1)\n",
    "print(type(yesterday))\n",
    "print(yesterday)\n",
    "# print(type(datetime.now()))\n",
    "# print(datetime.now())\n",
    "# datetime_object = datetime.strptime(datetime_str, '%d/%m/%y')\n",
    "# print(datetime_object - timedelta(1))\n",
    "\n",
    "print(datetime.strftime(yesterday, '%d/%m/%y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n",
      "2023-04-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "input_date = \"01/04/2023\"\n",
    "datetime_object = datetime.strptime(input_date, '%d/%m/%Y')\n",
    "print(type(datetime_object))\n",
    "print(datetime_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount in dollar-cent format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dollars\n",
      "100 dollars and 89 cents\n"
     ]
    }
   ],
   "source": [
    "def get_amount(num):\n",
    "    if type(num) == type(10):\n",
    "        \n",
    "        txt = f\"{num} dollars\"\n",
    "    else:\n",
    "        a = \"{0:.2f}\".format(num)\n",
    "        l = a.split(\".\")\n",
    "        txt = f\"{l[0]} dollars and {l[1]} cents\"\n",
    "    return txt\n",
    "    \n",
    "print(get_amount(100))\n",
    "print(get_amount(100.89))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd : relativedelta(weekday=FR(+2))\n",
      "2023-07-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_next_friday():\n",
    "    import datetime as DT\n",
    "    import dateutil.relativedelta as REL\n",
    "    \n",
    "    # today = DT.date.today()\n",
    "    # print(today)\n",
    "    # print(type(today))\n",
    "    today = DT.datetime.strptime(\"2023/06/24\", \"%Y/%m/%d\")\n",
    "    # print(today)\n",
    "    # print(type(today))\n",
    "    # 2012-01-10\n",
    "    # rd = REL.relativedelta(days=7, weekday=REL.FR)\n",
    "    rd = REL.relativedelta(weekday=REL.FR(2))\n",
    "    print(f\"rd : {rd}\")\n",
    "    next_friday = today + rd\n",
    "    \n",
    "    # 2012-01-13\n",
    "    \n",
    "    return next_friday\n",
    "    \n",
    "print(get_next_friday())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---> add audio in utterance and at the end ask are you there..........\n",
    "# ---> multiple voice in the same bot based on key work like angry, sad and anyother....\n",
    "# ---> language identification based on user's response..........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28-06-2023\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "def get_input_date():\n",
    "    import datetime\n",
    "    from datetime import date\n",
    "\n",
    "    today = date.today()\n",
    "    formatted_today = today.strftime(\"%d-%m-%Y\")\n",
    "    # formatted_today = \"26-06-2023\"\n",
    "    day = formatted_today.split(\"-\")[0]\n",
    "    month = formatted_today.split(\"-\")[1]\n",
    "    year = formatted_today.split(\"-\")[2]\n",
    "\n",
    "    if 5<= int(day) <= 10:\n",
    "        input_date = f\"05-{month}-{year}\"\n",
    "    elif 20 <= int(day) <= 25:\n",
    "        input_date = f\"20-{month}-{year}\"\n",
    "    else:\n",
    "        input_date = formatted_today\n",
    "    \n",
    "    return input_date\n",
    "\n",
    "\n",
    "print(get_input_date())\n",
    "print(type(get_input_date()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package crubadan to /home/darshan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/crubadan.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('crubadan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to /home/darshan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/udhr.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('udhr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language snippet:  Danezana gerdûnî ya mafên mirov Dîbaçe Herwekî nasîna weqara pêgirê hemû endamên malbata mirovî û mafên wan ên wekhev û ( jênager ) bingehe...\n",
      "Language detection: kmr (Northern Kurdish)\n",
      "############################################################################################################################################\n",
      "Language snippet:  Ауаюытъыюса изин6ъа Зегьеицырзеи8шу Адекларациа Алагалажъа Дызус0заалак , ауаатъыюсатъ 0аацъара иалахъу ища0ыри , иара иузийъым0хо имоу изи...\n",
      "Language detection: abk (Abkhazian)\n",
      "############################################################################################################################################\n",
      "Language snippet:  اعلامیه جهاني حقوق بشر مقدمه از آنجا که شناسائی حيثيت ذاتی کليـه اعضای خانواده بشری و حقوق يکسان و انتقال ناپـذير آنـان اساس آزادي و عدالت ...\n",
      "Language detection: pes (Iranian Persian)\n",
      "############################################################################################################################################\n",
      "Language snippet:  ﻿ म ा नव अध ि क ा र ों क ी स ा र ् वभ ौ म घ ो षण ा १० द ि सम ् बल १९४८ क ो य ू न ा‌ इट े ड न े शन ् स क ी जनरल अस े म ् बल ी न े म ा नव अध ...\n",
      "Language detection: hin (Hindi)\n",
      "############################################################################################################################################\n",
      "Language snippet:  I ka lā 10 o Dēkēmapa , M . H . 1948 , ua ho ’ oholo a kaūkala ka ‘ Aha ‘ Ōlelo o Nā Aupuni Hui Pū ‘ Ia i ka Hō ’ ike No Nā Pono Kanaka O K...\n",
      "Language detection: haw (Hawaiian)\n",
      "############################################################################################################################################\n",
      "Language snippet:  Всеобщая декларация прав человека Принята и провозглашена резолюцией 217 А ( III ) Генеральной Ассамблеи от 10 декабря 1948 года . ПРЕАМБУЛ...\n",
      "Language detection: rus (Russian)\n",
      "############################################################################################################################################\n",
      "Language snippet:  Tuyên ngôn toàn thế giới về nhân quyền của Liên Hợp Quốc Được Đại hội đồng Liên Hợp Quốc thông qua và công bố theo Nghị quyết số 217 ( III ...\n",
      "Language detection: vie (Vietnamese)\n",
      "############################################################################################################################################\n",
      "Language snippet:  OПШTA ДEKЛAPAЦИJAO ПPABИMA ЧOBEKA УBOД Пoштo je признaвaњe урoђeнoг дoстojaнствa и jeднaких и нeoтуђивих прaвa свих члaнoвa људскe пoрoдицe...\n",
      "Language detection: srp (Serbian)\n",
      "############################################################################################################################################\n",
      "Language snippet:  Universala Deklaracio de Homaj Rajtoj Adoptita kaj proklamita de Rezolucio 217 A ( III ) de la Ĝenerala Asembleo , 10an de decembro 1948 An...\n",
      "Language detection: epo (Esperanto)\n",
      "############################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Toolkit: Language ID module using TextCat algorithm\n",
    "#\n",
    "# Copyright (C) 2001-2023 NLTK Project\n",
    "# Author: Avital Pekker <avital.pekker@utoronto.ca>\n",
    "#\n",
    "# URL: <https://www.nltk.org/>\n",
    "# For license information, see LICENSE.TXT\n",
    "\n",
    "\"\"\"\n",
    "A module for language identification using the TextCat algorithm.\n",
    "An implementation of the text categorization algorithm\n",
    "presented in Cavnar, W. B. and J. M. Trenkle,\n",
    "\"N-Gram-Based Text Categorization\".\n",
    "\n",
    "The algorithm takes advantage of Zipf's law and uses\n",
    "n-gram frequencies to profile languages and text-yet to\n",
    "be identified-then compares using a distance measure.\n",
    "\n",
    "Language n-grams are provided by the \"An Crubadan\"\n",
    "project. A corpus reader was created separately to read\n",
    "those files.\n",
    "\n",
    "For details regarding the algorithm, see:\n",
    "https://www.let.rug.nl/~vannoord/TextCat/textcat.pdf\n",
    "\n",
    "For details about An Crubadan, see:\n",
    "https://borel.slu.edu/crubadan/index.html\n",
    "\"\"\"\n",
    "\n",
    "from sys import maxsize\n",
    "\n",
    "from nltk.util import trigrams\n",
    "\n",
    "# Note: this is NOT \"re\" you're likely used to. The regex module\n",
    "# is an alternative to the standard re module that supports\n",
    "# Unicode codepoint properties with the \\p{} syntax.\n",
    "# You may have to \"pip install regx\"\n",
    "try:\n",
    "    import regex as re\n",
    "except ImportError:\n",
    "    re = None\n",
    "######################################################################\n",
    "##  Language identification using TextCat\n",
    "######################################################################\n",
    "\n",
    "\n",
    "class TextCat:\n",
    "\n",
    "    _corpus = None\n",
    "    fingerprints = {}\n",
    "    _START_CHAR = \"<\"\n",
    "    _END_CHAR = \">\"\n",
    "\n",
    "    last_distances = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        if not re:\n",
    "            raise OSError(\n",
    "                \"classify.textcat requires the regex module that \"\n",
    "                \"supports unicode. Try '$ pip install regex' and \"\n",
    "                \"see https://pypi.python.org/pypi/regex for \"\n",
    "                \"further details.\"\n",
    "            )\n",
    "\n",
    "        from nltk.corpus import crubadan\n",
    "\n",
    "        self._corpus = crubadan\n",
    "        # Load all language ngrams into cache\n",
    "        for lang in self._corpus.langs():\n",
    "            self._corpus.lang_freq(lang)\n",
    "\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        \"\"\"Get rid of punctuation except apostrophes\"\"\"\n",
    "        return re.sub(r\"[^\\P{P}\\']+\", \"\", text)\n",
    "\n",
    "\n",
    "    def profile(self, text):\n",
    "        \"\"\"Create FreqDist of trigrams within text\"\"\"\n",
    "        from nltk import FreqDist, word_tokenize\n",
    "\n",
    "        clean_text = self.remove_punctuation(text)\n",
    "        tokens = word_tokenize(clean_text)\n",
    "\n",
    "        fingerprint = FreqDist()\n",
    "        for t in tokens:\n",
    "            token_trigram_tuples = trigrams(self._START_CHAR + t + self._END_CHAR)\n",
    "            token_trigrams = [\"\".join(tri) for tri in token_trigram_tuples]\n",
    "\n",
    "            for cur_trigram in token_trigrams:\n",
    "                if cur_trigram in fingerprint:\n",
    "                    fingerprint[cur_trigram] += 1\n",
    "                else:\n",
    "                    fingerprint[cur_trigram] = 1\n",
    "\n",
    "        return fingerprint\n",
    "\n",
    "\n",
    "    def calc_dist(self, lang, trigram, text_profile):\n",
    "        \"\"\"Calculate the \"out-of-place\" measure between the\n",
    "        text and language profile for a single trigram\"\"\"\n",
    "\n",
    "        lang_fd = self._corpus.lang_freq(lang)\n",
    "        dist = 0\n",
    "\n",
    "        if trigram in lang_fd:\n",
    "            idx_lang_profile = list(lang_fd.keys()).index(trigram)\n",
    "            idx_text = list(text_profile.keys()).index(trigram)\n",
    "\n",
    "            # print(idx_lang_profile, \", \", idx_text)\n",
    "            dist = abs(idx_lang_profile - idx_text)\n",
    "        else:\n",
    "            # Arbitrary but should be larger than\n",
    "            # any possible trigram file length\n",
    "            # in terms of total lines\n",
    "            dist = maxsize\n",
    "\n",
    "        return dist\n",
    "\n",
    "\n",
    "    def lang_dists(self, text):\n",
    "        \"\"\"Calculate the \"out-of-place\" measure between\n",
    "        the text and all languages\"\"\"\n",
    "\n",
    "        distances = {}\n",
    "        profile = self.profile(text)\n",
    "        # For all the languages\n",
    "        for lang in self._corpus._all_lang_freq.keys():\n",
    "            # Calculate distance metric for every trigram in\n",
    "            # input text to be identified\n",
    "            lang_dist = 0\n",
    "            for trigram in profile:\n",
    "                lang_dist += self.calc_dist(lang, trigram, profile)\n",
    "\n",
    "            distances[lang] = lang_dist\n",
    "\n",
    "        return distances\n",
    "\n",
    "\n",
    "    def guess_language(self, text):\n",
    "        \"\"\"Find the language with the min distance\n",
    "        to the text and return its ISO 639-3 code\"\"\"\n",
    "        self.last_distances = self.lang_dists(text)\n",
    "\n",
    "        return min(self.last_distances, key=self.last_distances.get)\n",
    "\n",
    "        #################################################')\n",
    "\n",
    "\n",
    "def demo():\n",
    "    from nltk.corpus import udhr\n",
    "\n",
    "    langs = [\n",
    "        \"Kurdish-UTF8\",\n",
    "        \"Abkhaz-UTF8\",\n",
    "        \"Farsi_Persian-UTF8\",\n",
    "        \"Hindi-UTF8\",\n",
    "        \"Hawaiian-UTF8\",\n",
    "        \"Russian-UTF8\",\n",
    "        \"Vietnamese-UTF8\",\n",
    "        \"Serbian_Srpski-UTF8\",\n",
    "        \"Esperanto-UTF8\",\n",
    "    ]\n",
    "\n",
    "    friendly = {\n",
    "        \"kmr\": \"Northern Kurdish\",\n",
    "        \"abk\": \"Abkhazian\",\n",
    "        \"pes\": \"Iranian Persian\",\n",
    "        \"hin\": \"Hindi\",\n",
    "        \"haw\": \"Hawaiian\",\n",
    "        \"rus\": \"Russian\",\n",
    "        \"vie\": \"Vietnamese\",\n",
    "        \"srp\": \"Serbian\",\n",
    "        \"epo\": \"Esperanto\",\n",
    "    }\n",
    "\n",
    "    tc = TextCat()\n",
    "\n",
    "    for cur_lang in langs:\n",
    "        # Get raw data from UDHR corpus\n",
    "        raw_sentences = udhr.sents(cur_lang)\n",
    "        rows = len(raw_sentences) - 1\n",
    "        cols = list(map(len, raw_sentences))\n",
    "\n",
    "        sample = \"\"\n",
    "\n",
    "        # Generate a sample text of the language\n",
    "        for i in range(0, rows):\n",
    "            cur_sent = \"\"\n",
    "            for j in range(0, cols[i]):\n",
    "                cur_sent += \" \" + raw_sentences[i][j]\n",
    "\n",
    "            sample += cur_sent\n",
    "\n",
    "        # Try to detect what it is\n",
    "        print(\"Language snippet: \" + sample[0:140] + \"...\")\n",
    "        guess = tc.guess_language(sample)\n",
    "        print(f\"Language detection: {guess} ({friendly[guess]})\")\n",
    "        print(\"#\" * 140)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jun\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "month_mapping = {\n",
    "    \"01\": \"Jan\",\n",
    "    \"02\": \"Feb\",\n",
    "    \"03\": \"Mar\",\n",
    "    \"04\": \"Apr\",\n",
    "    \"05\": \"May\",\n",
    "    \"06\": \"Jun\",\n",
    "    \"07\": \"Jul\",\n",
    "    \"08\": \"Aug\",\n",
    "    \"09\": \"Sep\",\n",
    "    \"10\": \"Oct\",\n",
    "    \"11\": \"Nov\",\n",
    "    \"12\": \"Dec\"\n",
    "}\n",
    "\n",
    "month_mapping_reverse = {\n",
    "    \"Jan\": \"01\",\n",
    "    \"Feb\": \"02\",\n",
    "    \"Mar\": \"03\",\n",
    "    \"Apr\": \"04\",\n",
    "    \"May\": \"05\",\n",
    "    \"Jun\": \"06\",\n",
    "    \"Jul\": \"07\",\n",
    "    \"Aug\": \"08\",\n",
    "    \"Sep\": \"09\",\n",
    "    \"Oct\": \"10\",\n",
    "    \"Nov\": \"11\",\n",
    "    \"Dec\": \"12\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_previous_month():\n",
    "    today = datetime.date.today()\n",
    "    first = today.replace(day=1)\n",
    "    last_month = first - datetime.timedelta(days=1)\n",
    "    month = last_month.strftime(\"%m\")\n",
    "    year = last_month.strftime(\"%Y\")\n",
    "    return year, month\n",
    "\n",
    "\n",
    "def get_month_name(month):\n",
    "    return month_mapping[month]\n",
    "\n",
    "year, month = get_previous_month()\n",
    "print(get_month_name(month))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 00:00:00.890888+05:30 \n",
      " 2023-12-31 23:59:59.890888+05:30\n"
     ]
    }
   ],
   "source": [
    "month_mapping_reverse = {\n",
    "    \"January\": \"01\",\n",
    "    \"February\": \"02\",\n",
    "    \"March\": \"03\",\n",
    "    \"April\": \"04\",\n",
    "    \"May\": \"05\",\n",
    "    \"June\": \"06\",\n",
    "    \"July\": \"07\",\n",
    "    \"August\": \"08\",\n",
    "    \"September\": \"09\",\n",
    "    \"October\": \"10\",\n",
    "    \"November\": \"11\",\n",
    "    \"December\": \"12\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_previous_month():\n",
    "    today = datetime.date.today()\n",
    "    first = today.replace(day=1)\n",
    "    last_month = first - datetime.timedelta(days=1)\n",
    "    month = last_month.strftime(\"%m\")\n",
    "    month_name = last_month.strftime(\"%B\")\n",
    "    year = last_month.strftime(\"%Y\")\n",
    "    return year, month, month_name\n",
    "\n",
    "def get_first_and_last_date_of_month(month_name):\n",
    "    import calendar\n",
    "    import datetime\n",
    "    import pytz\n",
    "    month = int((month_mapping_reverse[month_name]).lstrip(\"0\"))\n",
    "    first_day, day_count = calendar.monthrange(2023, month)\n",
    "\n",
    "    # on 1st of every month it will pick last month's details\n",
    "    yesterday = datetime.datetime.now(pytz.timezone(\n",
    "        'Asia/Kolkata')) - datetime.timedelta(days=1)\n",
    "    first_day = yesterday.replace(\n",
    "        month=month, day=1, hour=0, minute=0, second=0)\n",
    "    last_day = yesterday.replace(\n",
    "        month=month, day=day_count, hour=23, minute=59, second=59)\n",
    "    # print(\"starting date : \",first_day,\"\\nending date : \",last_day)\n",
    "    return first_day, last_day\n",
    "\n",
    "a,b = get_first_and_last_date_of_month(\"December\")\n",
    "print(a,\"\\n\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Python program to demonstrate working of key\n",
    "# value change in OrderedDict\n",
    "def od():\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    print(\"Before:\\n\")\n",
    "    od = OrderedDict()\n",
    "    od['a'] = 1\n",
    "    od['b'] = 2\n",
    "    od['c'] = 3\n",
    "    od['d'] = 4\n",
    "    for key, value in od.items():\n",
    "        print(key, value)\n",
    "\n",
    "    print(\"\\nAfter:\\n\")\n",
    "    od['c'] = 5\n",
    "    for key, value in od.items():\n",
    "        print(key, value)\n",
    "\n",
    "def basic():\n",
    "    print(\"................. without collection ..................\")\n",
    "    bc = {}\n",
    "    bc['a'] = 1\n",
    "    bc['b'] = 2\n",
    "    bc['c'] = 3\n",
    "    bc['d'] = 4\n",
    "    for key, value in bc.items():\n",
    "        print(key, value)\n",
    "\n",
    "    print(\"\\nAfter:\\n\")\n",
    "    bc['c'] = 5\n",
    "    for key, value in bc.items():\n",
    "        print(key, value)\n",
    "\n",
    "od()\n",
    "basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21\n",
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.date.today()\n",
    "print(today)\n",
    "print(type(today))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a = {\n",
    "    1:'c',\n",
    "    5:'b',\n",
    "    2:'a'\n",
    "}\n",
    "\n",
    "for i in sorted(a.keys()):\n",
    "    print(i)\n",
    "    # print(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'c'), (2, 'a'), (5, 'b')]\n",
      "[(2, 'a'), (5, 'b'), (1, 'c')]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(a.items(), key=lambda x: x[0]))\n",
    "print(sorted(a.items(), key=lambda x: x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
