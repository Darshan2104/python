{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69947035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangGraph!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangGraph!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f106e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409db107",
   "metadata": {},
   "source": [
    "## Basic LangGraph\n",
    "- Node\n",
    "- Edge\n",
    "- starting point and ending point\n",
    "- Visualization of graph and stream of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8a0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(input):\n",
    "    return \"Function f1 : \"+input\n",
    "\n",
    "def f2(input):\n",
    "    return \"Function f2 : \"+input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb37ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee44a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x10bb8f590>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"f1\", f1)\n",
    "workflow.add_node(\"f2\", f2)\n",
    "workflow.add_edge(\"f1\", \"f2\")\n",
    "workflow.set_entry_point(\"f1\")\n",
    "workflow.set_finish_point(\"f2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2499e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27cb62ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a598cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Function f2 : Function f1 : Hello World'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f15887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from key f1\n",
      "----\n",
      "Function f1 : Hello World\n",
      "\n",
      "\n",
      "Output from key f2\n",
      "----\n",
      "Function f2 : Function f1 : Hello World\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input=\"Hello World\"\n",
    "for output in app.stream(input):\n",
    "    for k,v in output.items():\n",
    "        print(f\"Output from key {k}\")\n",
    "        print(\"----\")\n",
    "        print(v)\n",
    "        print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43cf6779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FUNCTION F1 : HELLO WORLD'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(input):\n",
    "    return \"Function f1 : \"+input\n",
    "\n",
    "def upper_string(input):\n",
    "    return input.upper()\n",
    "\n",
    "workflow_1 = Graph()\n",
    "workflow_1.add_node(\"f1\", f1)\n",
    "workflow_1.add_node(\"upper_string\", upper_string)\n",
    "workflow_1.add_edge(\"f1\", \"upper_string\")\n",
    "workflow_1.set_entry_point(\"f1\")\n",
    "workflow_1.set_finish_point(\"upper_string\")\n",
    "app_1 = workflow_1.compile()\n",
    "app_1.invoke(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fc9e8",
   "metadata": {},
   "source": [
    "## Basic RAG Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2bbb7",
   "metadata": {},
   "source": [
    "### Basic setup\n",
    "- GoogleGenerativeAIEmbeddings\n",
    "- ChatGoogleGenerativeAI --> gemini-1.5-flash\n",
    "- ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb0bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48dd9b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vectors = embeddings.embed_documents(\n",
    "    [\n",
    "        \"Today is Monday\",\n",
    "        \"Today is Tuesday\",\n",
    "        \"Today is April Fools day\",\n",
    "    ]\n",
    ")\n",
    "len(vectors), len(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c0210fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9fa6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current Prime Minister of India is Narendra Modi.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--5b82c9ad-02d7-409d-b06e-0a9bc6ee983a-0', usage_metadata={'input_tokens': 12, 'output_tokens': 11, 'total_tokens': 23, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([\n",
    "    SystemMessage(\"For any given country you will return their prime minister name\"),\n",
    "    HumanMessage(\"India\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6a899e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "docs = DirectoryLoader(\".\", glob=\"*.txt\", show_progress=True).load() # loads all text files in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d9b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "new_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0797cfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='LangGraph is an open-source Python library developed by LangChain Inc. It enables the construction of stateful, multi-agent workflows for large language model (LLM) applications. Unlike traditional Directed Acyclic Graph (DAG) frameworks, LangGraph supports cycles and loops, making it ideal for complex, interactive agent behaviors.([geeksrepos.com][1], [Real Python][2], [Medium][3])\\n\\n---\\n\\n### 🔧 Key Features of LangGraph\\n\\n**Graph\\n\\nBased Architecture\\n\\n**: Define workflows as graphs with nodes (agents or functions) and edges (transitions), allowing for intricate control flows, including cycles and branching.\\n\\n**Stateful Execution\\n\\n**: Maintain and persist state across interactions, enabling long\\n\\nterm memory and context retention.\\n\\n**Human\\n\\nin\\n\\nthe\\n\\nLoop\\n\\n**: Incorporate human oversight by pausing execution for approvals or interventions, enhancing reliability.([geeksrepos.com][1])\\n\\n**Streaming Support\\n\\n**: Stream outputs token\\n\\nby\\n\\ntoken, providing real'),\n",
       " Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='**Streaming Support\\n\\n**: Stream outputs token\\n\\nby\\n\\ntoken, providing real\\n\\ntime feedback and improved user experience.([geeksrepos.com][1])\\n\\n**Integration with LangChain\\n\\n**: Seamlessly integrates with LangChain and LangSmith for enhanced observability and debugging, though it can function independently.([geeksrepos.com][1])\\n\\n---\\n\\n### 🧠 Use Cases\\n\\n**Chatbots\\n\\n**: Develop sophisticated chatbots capable of handling diverse user queries while maintaining context.([DataCamp][4])\\n\\n**Autonomous Agents\\n\\n**: Create agents that perform tasks independently based on user inputs and predefined logic.([DataCamp][4])\\n\\n**Multi\\n\\nAgent Systems\\n\\n**: Design systems where multiple agents collaborate to achieve complex goals, such as in supply chain management.([DataCamp][4])\\n\\n**Workflow Automation\\n\\n**: Automate business processes like document processing and data analysis with intelligent agents.([DataCamp][4])\\n\\n**Recommendation Systems'),\n",
       " Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='**Workflow Automation\\n\\n**: Automate business processes like document processing and data analysis with intelligent agents.([DataCamp][4])\\n\\n**Recommendation Systems\\n\\n**: Build personalized recommendation engines by analyzing user behavior and preferences.\\n\\n**Personalized Learning Environments\\n\\n**: Develop adaptive educational platforms that cater to individual learning styles and progress.([DataCamp][4])\\n\\n---\\n\\n### 🚀 Getting Started\\n\\nTo install LangGraph:\\n\\n```bash\\n\\npip install\\n\\nU langgraph\\n\\n```\\n\\nHere\\'s a simple example of creating a ReAct agent using LangGraph:([Langchain][5])\\n\\n```python\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\ndef search(query: str): \"\"\"Simulate a web search.\"\"\" if \"sf\" in query.lower() or \"san francisco\" in query.lower(): return \"It\\'s 60 degrees and foggy.\" return \"It\\'s 90 degrees and sunny.\"'),\n",
       " Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='def search(query: str): \"\"\"Simulate a web search.\"\"\" if \"sf\" in query.lower() or \"san francisco\" in query.lower(): return \"It\\'s 60 degrees and foggy.\" return \"It\\'s 90 degrees and sunny.\"\\n\\nagent = create_react_agent(\"anthropic:claude-3-7-sonnet-latest\", tools=[search]) response = agent.invoke( {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]} ) print(response) ```\\n\\n---\\n\\n### 🏗️ LangGraph Platform\\n\\nFor deploying LangGraph applications at scale, LangChain Inc. offers the LangGraph Platform, which includes:([LangChain Blog][6])\\n\\n**LangGraph Server\\n\\n**: APIs for managing agents, memory, and execution.([Langchain][5])\\n\\n**LangGraph Studio\\n\\n**: A UI for visualizing and debugging agent workflows.([LangChain Blog][6])\\n\\n**Deployment Options\\n\\n**:\\n\\n**Cloud SaaS\\n\\n**: Fully managed service.\\n\\n**Self\\n\\nHosted Lite\\n\\n**: Free version for local or self\\n\\nhosted deployments.\\n\\n**Bring Your Own Cloud (BYOC)\\n\\n**: Run in your own cloud environment with LangChain managing provisioning.'),\n",
       " Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='**Self\\n\\nHosted Lite\\n\\n**: Free version for local or self\\n\\nhosted deployments.\\n\\n**Bring Your Own Cloud (BYOC)\\n\\n**: Run in your own cloud environment with LangChain managing provisioning.\\n\\n**Self\\n\\nHosted Enterprise\\n\\n**: Fully self\\n\\nmanaged deployment.([LangChain Blog][6], [Analytics Vidhya][7], [LangChain][8])\\n\\n---\\n\\n### 📚 Learn More\\n\\n**Official Documentation\\n\\n**: [LangGraph Docs](https://langchain\\n\\nai.github.io/langgraph/)([Langchain][5])\\n\\n**LangChain Academy Course\\n\\n**: [Introduction to LangGraph](https://www.langchain.com/langgraph)([LangChain][8])\\n\\n**GitHub Repository\\n\\n**: [LangGraph on GitHub](https://github.com/langchain\\n\\nai/langgraph)([geeksrepos.com][1])\\n\\n**Tutorial\\n\\n**: [LangGraph Tutorial on DataCamp](https://www.datacamp.com/tutorial/langgraph\\n\\ntutorial)([DataCamp][4])\\n\\n---\\n\\nLangGraph empowers developers to build robust, controllable, and stateful AI agents, making it a valuable tool for complex LLM applications.([Real Python][2])'),\n",
       " Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='[1]: https://geeksrepos.com/langchain-ai/langgraph?utm_source=chatgpt.com \"langgraph: A Python repository from LangChain - LangChain\" [2]: https://realpython.com/langgraph-python/?utm_source=chatgpt.com \"LangGraph: Build Stateful AI Agents in Python – Real Python\" [3]: https://bhavikjikadara.medium.com/langgraph-a-comprehensive-guide-for-beginners-ef17d3dd5383?utm_source=chatgpt.com \"LangGraph: A Comprehensive Guide for Beginners | by Bhavik Jikadara | Medium\" [4]: https://www.datacamp.com/tutorial/langgraph-tutorial?utm_source=chatgpt.com \"LangGraph Tutorial: What Is LangGraph and How to Use It? | DataCamp\" [5]: https://langchain-ai.github.io/langgraph/?utm_source=chatgpt.com \"Home\" [6]: https://blog.langchain.dev/langgraph-platform-announce/?utm_source=chatgpt.com \"LangGraph Platform: New deployment options for scalable agent infrastructure\" [7]: https://www.analyticsvidhya.com/blog/2025/05/langgraph-tutorial-for-beginners/?utm_source=chatgpt.com \"LangGraph Tutorial for Beginners\"'),\n",
       " Document(metadata={'source': 'langgraph_sample_kb.txt'}, page_content='New deployment options for scalable agent infrastructure\" [7]: https://www.analyticsvidhya.com/blog/2025/05/langgraph-tutorial-for-beginners/?utm_source=chatgpt.com \"LangGraph Tutorial for Beginners\" [8]: https://www.langchain.com/langgraph?utm_source=chatgpt.com \"LangGraph\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97e2cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(new_docs, embeddings, persist_directory=\"chroma_db\")\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e847476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/brsg9wgd0wbbdymjwnpjnv_h0000gn/T/ipykernel_16798/3343993480.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'langgraph_sample_kb.txt'}\n",
      "LangGraph is an open-source Python library developed by LangChain Inc. It enables the construction of stateful, multi-agent workflows for large language model (LLM) applications. Unlike traditional Directed Acyclic Graph (DAG) frameworks, LangGraph supports cycles and loops, making it ideal for complex, interactive agent behaviors.([geeksrepos.com][1], [Real Python][2], [Medium][3])\n",
      "\n",
      "---\n",
      "\n",
      "### 🔧 Key Features of LangGraph\n",
      "\n",
      "**Graph\n",
      "\n",
      "Based Architecture\n",
      "\n",
      "**: Define workflows as graphs with nodes (agents or functions) and edges (transitions), allowing for intricate control flows, including cycles and branching.\n",
      "\n",
      "**Stateful Execution\n",
      "\n",
      "**: Maintain and persist state across interactions, enabling long\n",
      "\n",
      "term memory and context retention.\n",
      "\n",
      "**Human\n",
      "\n",
      "in\n",
      "\n",
      "the\n",
      "\n",
      "Loop\n",
      "\n",
      "**: Incorporate human oversight by pausing execution for approvals or interventions, enhancing reliability.([geeksrepos.com][1])\n",
      "\n",
      "**Streaming Support\n",
      "\n",
      "**: Stream outputs token\n",
      "\n",
      "by\n",
      "\n",
      "token, providing real\n"
     ]
    }
   ],
   "source": [
    "query = \"What is langgraph?\"\n",
    "\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(results[0].metadata)\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d255ca",
   "metadata": {},
   "source": [
    "### Use it in Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b299dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(AgentState):\n",
    "    message = AgentState[\"message\"]\n",
    "    question = message[-1]\n",
    "    prompt = f\"Your task is to give brief answer to the question: {question}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    AgentState[\"message\"].append(response.content)\n",
    "    return AgentState\n",
    "\n",
    "def f2(AgentState):\n",
    "    question = AgentState[\"message\"][0] # User question\n",
    "\n",
    "    prompt_template = \"\"\"Answer the question based on following context: \n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    retrival_chain = (\n",
    "        {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    retuslt = retrival_chain.invoke(question)\n",
    "    return retuslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9acb168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_basic_rag = Graph()\n",
    "workflow_basic_rag.add_node(\"llm\", f1)\n",
    "workflow_basic_rag.add_node(\"retriever\", f2)\n",
    "workflow_basic_rag.add_edge(\"llm\", \"retriever\")\n",
    "workflow_basic_rag.set_entry_point(\"llm\")\n",
    "workflow_basic_rag.set_finish_point(\"retriever\")\n",
    "\n",
    "app_basic_rag = workflow_basic_rag.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fcf2ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "try:\n",
    "    display(Image(app_basic_rag.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c236e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangGraph is an open-source Python library developed by LangChain Inc.  It's used to build stateful, multi-agent workflows for large language model (LLM) applications.  Unlike traditional DAG frameworks, it supports cycles and loops, making it suitable for complex, interactive agent behaviors.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"message\": [\"What is LangGraph?\"]}\n",
    "app_basic_rag.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0e37170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from key llm\n",
      "----\n",
      "{'message': ['What is LangGraph?', 'LangGraph is a knowledge graph representing the relationships between programming languages.']}\n",
      "\n",
      "\n",
      "Output from key retriever\n",
      "----\n",
      "LangGraph is an open-source Python library developed by LangChain Inc.  It's used to build stateful, multi-agent workflows for large language model (LLM) applications.  Unlike traditional DAG frameworks, it supports cycles and loops, making it suitable for complex, interactive agent behaviors.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"message\": [\"What is LangGraph?\"]\n",
    "}\n",
    "for output in app_basic_rag.stream(input):\n",
    "    for k,v in output.items():\n",
    "        print(f\"Output from key {k}\")\n",
    "        print(\"----\")\n",
    "        print(v)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feca386",
   "metadata": {},
   "source": [
    "### Flow where it will take a call which one to use : RAG or directly LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f49fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5a46735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    message: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description=\"Selected topic\")\n",
    "    Reason: str = Field(description=\"Reason behind the topic selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76c8adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e4381c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"Selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reason\": {\"description\": \"Reason behind the topic selection\", \"title\": \"Reason\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reason\"]}\\n```'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf23903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(state):\n",
    "    message = state[\"message\"]\n",
    "    question = message[-1]\n",
    "    \n",
    "    template = \"\"\"Classify given query into one of the given category : [LangGraph, Not Related]. \n",
    "    Only return the selected category.\n",
    "    User query: {question}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template,\n",
    "                                          partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "                                          )\n",
    "    \n",
    "    #  prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # retrival_chain = (\n",
    "    #     {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    #     | prompt\n",
    "    #     | llm \n",
    "    #     | StrOutputParser()\n",
    "    #     )\n",
    "    \n",
    "    # retuslt = retrival_chain.invoke(question)\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    print(response)\n",
    "    state[\"message\"].append(response.Topic)\n",
    "    print(\"inside f1 after update: \",state)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee75f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(state):\n",
    "    message = state[\"message\"]\n",
    "    topic = message[-1]    \n",
    "    if \"langgraph\" == topic.lower():\n",
    "        return \"retriever_flow\"\n",
    "    else:\n",
    "        return \"llm_flow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d342e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(state):\n",
    "    print(\"RAG function--->\")\n",
    "    print(state)\n",
    "    question = state[\"message\"][0] # User question\n",
    "    template = \"\"\"Answer the question based on following context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    retrieval_chain = (\n",
    "        {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = retrieval_chain.invoke(question)\n",
    "    return {\"message\":[result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dbe88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(state):\n",
    "    print(\"LLM function--->\")\n",
    "    question = state[\"message\"][0] # User question\n",
    "    \n",
    "    prompt = f\"Your task is to give brief answer to the question: {question}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"message\":[response.content]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b5c2fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AgentState"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "929182c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "workflow_basic_rag_decision = StateGraph(AgentState)\n",
    "\n",
    "workflow_basic_rag_decision.add_edge(START, \"Agent\")\n",
    "workflow_basic_rag_decision.add_node(\"Agent\", f1)\n",
    "workflow_basic_rag_decision.add_node(\"retriever\", f2)\n",
    "workflow_basic_rag_decision.add_node(\"llm\", f3)\n",
    "\n",
    "\n",
    "workflow_basic_rag_decision.add_conditional_edges(\n",
    "    \"Agent\",\n",
    "    route,\n",
    "    {\n",
    "        \"retriever_flow\": \"retriever\",\n",
    "        \"llm_flow\": \"llm\"\n",
    "    })\n",
    "workflow_basic_rag_decision.add_edge(\"retriever\", END)\n",
    "workflow_basic_rag_decision.add_edge(\"llm\",END)\n",
    "\n",
    "app_basic_rag_decision = workflow_basic_rag_decision.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b5fbba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      +-----------+         \n",
      "      | __start__ |         \n",
      "      +-----------+         \n",
      "            *               \n",
      "            *               \n",
      "            *               \n",
      "        +-------+           \n",
      "        | Agent |           \n",
      "        +-------+           \n",
      "        .       .           \n",
      "      ..         ..         \n",
      "     .             .        \n",
      "+-----+       +-----------+ \n",
      "| llm |       | retriever | \n",
      "+-----+*      +-----------+ \n",
      "        *       *           \n",
      "         **   **            \n",
      "           * *              \n",
      "      +---------+           \n",
      "      | __end__ |           \n",
      "      +---------+           \n",
      "No image data found. Expecting filename, url, or data.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "try:\n",
    "    display(Image(app_basic_rag_decision.get_graph().print_ascii()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a31ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic='LangGraph' Reason='The query directly asks for the definition of LangGraph.'\n",
      "inside f1 after update:  {'message': ['What is LangGraph?', 'LangGraph']}\n",
      "RAG function--->\n",
      "{'message': ['What is LangGraph?', 'LangGraph', 'What is LangGraph?', 'LangGraph']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': ['What is LangGraph?',\n",
       "  'LangGraph',\n",
       "  'What is LangGraph?',\n",
       "  'LangGraph',\n",
       "  \"LangGraph is an open-source Python library developed by LangChain Inc.  It's used to build stateful, multi-agent workflows for large language model (LLM) applications.  Unlike traditional DAG frameworks, it supports cycles and loops, making it suitable for complex, interactive agent behaviors.\"]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\n",
    "    \"message\": [\"What is LangGraph?\"]\n",
    "}\n",
    "app_basic_rag_decision.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81521223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic='Not Related' Reason='LlamaIndex is not related to LangGraph.'\n",
      "inside f1 after update:  {'message': ['What is LlamaIndex?', 'Not Related']}\n",
      "LLM function--->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': ['What is LlamaIndex?',\n",
       "  'Not Related',\n",
       "  'What is LlamaIndex?',\n",
       "  'Not Related',\n",
       "  'LlamaIndex is an open-source framework for building LLM applications on your own data.']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\n",
    "    \"message\": [\"What is LlamaIndex?\"]\n",
    "}\n",
    "app_basic_rag_decision.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8719baf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic='Not Related' Reason='LlamaIndex is a framework for building LLM applications, not directly related to LangGraph.'\n",
      "inside f1 after update:  {'message': ['What is LlamaIndex?', 'Not Related']}\n",
      "Output from key Agent\n",
      "----\n",
      "{'message': ['What is LlamaIndex?', 'Not Related']}\n",
      "\n",
      "\n",
      "LLM function--->\n",
      "Output from key llm\n",
      "----\n",
      "{'message': ['LlamaIndex is an open-source framework for building LLM applications on your own data.']}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in app_basic_rag_decision.stream(input):\n",
    "    for k,v in output.items():\n",
    "        print(f\"Output from key {k}\")\n",
    "        print(\"----\")\n",
    "        print(v)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b42d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe0ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
